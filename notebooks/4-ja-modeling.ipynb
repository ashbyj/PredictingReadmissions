{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b34394",
   "metadata": {},
   "source": [
    "# todo\n",
    "- continue notes\n",
    "- visualize output of random forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227124b1",
   "metadata": {},
   "source": [
    "## contents\n",
    "* [introduction](#introduction)\n",
    "* [imports, load and model setup](#imports)\n",
    "* [naive bayes](#naive_bayes')\n",
    "* [logistic regression](#logistic_regression)\n",
    "* [random forest](#random_forest)\n",
    "* [AdaBoost](#adaboost)\n",
    "* [support vector machine](#svm)\n",
    "* [model selection and conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76eb4768",
   "metadata": {},
   "source": [
    "## introduction <a id='introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e018a",
   "metadata": {},
   "source": [
    "The ideal use case for this model would be to identify what features of the available data set are the best predictors of a patient's readmission.  This could then inform clinicians on what to focus on during the inpatient stay.  For the single patient, any changes to care driven by this analysis would be good, so focusing on scoring models by the true positive rate would be ideal for this case.  However, as this would be used to inform clinician practice, alert fatigue should also be considered and the false positive rate must also be considered.  Tuning to the optimial threshold would be best left for the organization implementing the model and during the monitoring phase. \n",
    "\n",
    "For these reasons, the area under (AUC) then receiver operating characteristic (ROC) curve will be used to score models and visualized to understand the shape of that curve.  The relative importance of each feature will also be included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a185373",
   "metadata": {},
   "source": [
    "## imports, load and model setup<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64916c44-85e8-4398-ba19-92174bf634cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from sklearnex import patch_sklearn, config_context\n",
    "patch_sklearn()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c4c4a-95af-4b34-b848-4aced0d72cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('../data/interim/X_train.parquet')\n",
    "X_test = pd.read_parquet('../data/interim/X_test.parquet')\n",
    "y_train = pd.read_parquet('../data/interim/y_train.parquet')\n",
    "y_test = pd.read_parquet('../data/interim/y_test.parquet')\n",
    "\n",
    "X_train_ind = X_train[X_train['is_independent'] == 1].copy()\n",
    "X_test_ind = X_test[X_test['is_independent'] == 1].copy()\n",
    "y_train_ind = y_train[y_train['is_independent'] == 1].copy()\n",
    "y_test_ind = y_test[y_test['is_independent'] == 1].copy()\n",
    "\n",
    "dataframes = [X_train, X_test, y_train, y_test, X_train_ind, X_test_ind, y_train_ind, y_test_ind]\n",
    "for df in dataframes:\n",
    "    df.drop('is_independent', axis=1, inplace=True)\n",
    "\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "y_train_ind = np.ravel(y_train_ind)\n",
    "y_test_ind = np.ravel(y_test_ind)\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedda295-7be7-49ee-a5d3-ee123190c2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sk_model(param_grid, model, cv, gpu=True, independent=False):\n",
    "\n",
    "    X_train_local = X_train_ind if independent else X_train\n",
    "    y_train_local = y_train_ind if independent else y_train\n",
    "    X_test_local = X_test_ind if independent else X_test\n",
    "    y_test_local = y_test_ind if independent else y_test\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "            estimator=model, \n",
    "            param_grid=param_grid, \n",
    "            cv=cv)\n",
    "    \n",
    "    if gpu:\n",
    "        with config_context(target_offload=\"gpu:0\"):\n",
    "            grid_search.fit(X_train_local, y_train_local)\n",
    "    else:\n",
    "        grid_search.fit(X_train_local, y_train_local)\n",
    "        \n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict_proba(X_test_local)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test_local, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    print(f'Best parameters: {grid_search.best_params_}')\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.plot(fpr, tpr, color='darkOrange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1.05])\n",
    "    plt.xlabel('false positive rate')\n",
    "    plt.ylabel('true positive rate')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    return grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b0daf0-157f-40e7-9ca6-34d304b1112b",
   "metadata": {},
   "source": [
    "## naive bayes<a id='naive_bayes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f223d3",
   "metadata": {},
   "source": [
    "Naive Bayes will give a good baseline for other models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9cd8d-7590-489b-a235-4830fb9f66b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {}\n",
    "\n",
    "model = GaussianNB()\n",
    "sk_model(param_grid=param_grid,\n",
    "         model=model,\n",
    "         cv=5,\n",
    "         independent=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb018fc",
   "metadata": {},
   "source": [
    "The baseline for other models is an AUC of 0.61 and there is a slight left learn to the curve indicating that increasing the threshold should be with some caution as the risk of alert fatigue increases somewhat quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa7c4f-a615-4633-b44f-f9ee7096eb3f",
   "metadata": {},
   "source": [
    "## logistic regression<a id='logistic_regression'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175ab8a",
   "metadata": {},
   "source": [
    "As this is a binary classication problem, logistic regression is a logical next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b5f04e-dd91-410e-896f-beff1b7daf8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1','l2']\n",
    "}\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model = sk_model(param_grid=param_grid,\n",
    "                 model=model,\n",
    "                 cv=cross_validation,\n",
    "                 independent=True\n",
    ")\n",
    "\n",
    "coef = model.coef_[0]\n",
    "coef = pd.DataFrame({'feature': X_train_ind.columns, 'coefficient': coef})\n",
    "coef['abs'] = coef['coefficient'].abs()\n",
    "coef_df = coef.sort_values(by='abs', ascending=False)\n",
    "coef = coef_df.drop('abs', axis=1)\n",
    "coef.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e4cd9",
   "metadata": {},
   "source": [
    "- Unsurprisingly, whether or not the patient had another inpatient stay in the 12 months prior to this admission is the strongest predictor of a readmision.  \n",
    "- Emergency encounters also weigh heavily.  \n",
    "- It is unexpected that outpatient encounters have a positive coefficient however.  Ideally treatment in these settings would help to prevent inpatient admissions.  \n",
    "- The weight of number_diagnoses is not surprising: \"sicker\" people are more likely to need inpatient care.  \n",
    "- Admission type and source of other needs further investigation.  Perhaps, they should be removed during one hot encoding and the other categories created.  If these feature also has a high impact in the final model selection, this can be done.\n",
    "- The top end age bucket is not surprising and likely related to whether or not they are discharged to care.  \n",
    "- dx_cluster_5's weight is interesting and the dx codes with the strongest representation in that vector should be explored.\n",
    "- alpha_gluc_inhibitor_class_NO with a negative weight is likely impacted by an underlying factor.  Perhaps this drug class is prescribed more often for the illnesses in dx_cluster_5\n",
    "- race_Caucasion needs quite a bit of attention.  Is it that this is the result of racial bias in care or some other socio-demographic factor?  It could also have a genetic cause.  These are questions left to healthcare providers and administrators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3bd9ce",
   "metadata": {},
   "source": [
    "Logistic regression improves the AUC by 0.03 and removes the left lean giving a slower increase in alert fatigue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1213ee-b1bc-4d6b-8299-134d4fb961d2",
   "metadata": {},
   "source": [
    "## random forest<a id='random_forest'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c72243-3a3d-48c7-9435-b841eda37d61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "sk_model(param_grid=param_grid,\n",
    "         model=model,\n",
    "         cv=cross_validation,\n",
    "         independent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc7f893",
   "metadata": {},
   "source": [
    "talk about feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2707d2",
   "metadata": {},
   "source": [
    "Random forests perform slightly better than logistic regression with a similar behaviour for alert fatigue expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e9aae",
   "metadata": {},
   "source": [
    "## AdaBoost<a id='adaboost'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100, 200],  \n",
    "    'learning_rate': [0.5, 1, 1.5]\n",
    "}\n",
    "\n",
    "model = AdaBoostClassifier(random_state=42)\n",
    "\n",
    "sk_model(param_grid=param_grid,\n",
    "         model=model,\n",
    "         cv=cross_validation,\n",
    "         independent=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1863044",
   "metadata": {},
   "source": [
    "AdaBoost performs slightly worse than random forests and is similar to logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097b3e7",
   "metadata": {},
   "source": [
    "## support vector machine<a id='svm'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bdf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100, 1000],  \n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "    'kernel': ['rbf', 'poly', 'linear']\n",
    "}\n",
    "\n",
    "model = svm.SVC(random_state=42)\n",
    "\n",
    "sk_model(param_grid=param_grid,\n",
    "         model=model,\n",
    "         cv=cross_validation,\n",
    "         independent=False,\n",
    "         # intelex support not implemented for SVC yet\n",
    "         gpu=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a8d47",
   "metadata": {},
   "source": [
    "## conclusion <a id='conclusion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ea9a6",
   "metadata": {},
   "source": [
    "All of the models tested had very similar AUC metrics and were not able to predict readmission well from this data set.  If any of them were to be used, explainability in both how the model was select and trained and what the results mean should be considered.  Clinicians will want to understand the details behind the model before they use it to treat patients.  They would also appreciate what they could expect to see with alert fatigue in increases thresholds.  The easier it is to understand the model, the more comfortable they will be with it.  This is subjective, but in this case, the random forest would be an idea candidate to move forward.  \n",
    "\n",
    "MAKE CONCLUSIONS ON THE FEATURE IMPORTANCE OF ALL OF THE MODELS CONSIDERED TOGETHER."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
