{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exploratory data analysis<a id='3_Exploratory_Data_Analysis'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contents\n",
    "* [introduction](#introduction)\n",
    "* [imports and load](#imports_and_load)\n",
    "* [exploration](#exploration_start)\n",
    "    - [check for bias](#bias_check)\n",
    "        - [bias in race](#race)\n",
    "        - [type of diabetes](#type)\n",
    "    - [demographic visualizations](#demo_viz)\n",
    "    - [demographic readmit ratios](#demo_rat)\n",
    "    - [admission source and type](#admit_st)\n",
    "    - [preadmission measurements](#preadmit_metrics)\n",
    "        - [previous encounters](#prev_enc)\n",
    "        - [glucose measurements](#glu_meas)\n",
    "    - [numerical descriptions of admission](#num_)\n",
    "        - [time in hopsital](#tih)\n",
    "        - [number of lab procedures](#nlp)\n",
    "        - [number of procedures](#np)\n",
    "        - [number of medications](#nm)\n",
    "        - [number of diagnoses](#nd)\n",
    "    - [top 3 diagnoses](#dx)\n",
    "    - [medications](#meds)\n",
    "- [Wrap-up](#wrapUp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## introduction<a id='introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this analysis will be to understand this data more fully.  This exploration will inform modelling decisions and possibly reveal insights itself.  This work will include reviewing distributions, scaling, encoding and testing interactions.  Additional data may be merged during exploration as needed and available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports and load<a id='imports_and_load'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101727, 38)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>...</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>acarbose</th>\n",
       "      <th>miglitol</th>\n",
       "      <th>tolazamide</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2278392</th>\n",
       "      <td>8222157</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>physicial referral</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149190</th>\n",
       "      <td>55629189</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>emergency</td>\n",
       "      <td>home</td>\n",
       "      <td>emergency room</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64410</th>\n",
       "      <td>86047875</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>emergency</td>\n",
       "      <td>home</td>\n",
       "      <td>emergency room</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500364</th>\n",
       "      <td>82442376</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>emergency</td>\n",
       "      <td>home</td>\n",
       "      <td>emergency room</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16680</th>\n",
       "      <td>42519267</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>emergency</td>\n",
       "      <td>home</td>\n",
       "      <td>emergency room</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              patient_nbr             race  gender      age admission_type_id  \\\n",
       "encounter_id                                                                    \n",
       "2278392           8222157        Caucasian  Female   [0-10)             Other   \n",
       "149190           55629189        Caucasian  Female  [10-20)         emergency   \n",
       "64410            86047875  AfricanAmerican  Female  [20-30)         emergency   \n",
       "500364           82442376        Caucasian    Male  [30-40)         emergency   \n",
       "16680            42519267        Caucasian    Male  [40-50)         emergency   \n",
       "\n",
       "             discharge_disposition_id admission_source_id  time_in_hospital  \\\n",
       "encounter_id                                                                  \n",
       "2278392                         Other  physicial referral                 1   \n",
       "149190                           home      emergency room                 3   \n",
       "64410                            home      emergency room                 2   \n",
       "500364                           home      emergency room                 2   \n",
       "16680                            home      emergency room                 1   \n",
       "\n",
       "              num_lab_procedures  num_procedures  ...  pioglitazone  \\\n",
       "encounter_id                                      ...                 \n",
       "2278392                       41               0  ...            No   \n",
       "149190                        59               0  ...            No   \n",
       "64410                         11               5  ...            No   \n",
       "500364                        44               1  ...            No   \n",
       "16680                         51               0  ...            No   \n",
       "\n",
       "              rosiglitazone  acarbose  miglitol tolazamide insulin  \\\n",
       "encounter_id                                                         \n",
       "2278392                  No        No        No         No      No   \n",
       "149190                   No        No        No         No      Up   \n",
       "64410                    No        No        No         No      No   \n",
       "500364                   No        No        No         No      Up   \n",
       "16680                    No        No        No         No  Steady   \n",
       "\n",
       "             glyburide-metformin  change diabetesMed readmitted  \n",
       "encounter_id                                                     \n",
       "2278392                       No      No          No         NO  \n",
       "149190                        No      Ch         Yes        >30  \n",
       "64410                         No      No         Yes         NO  \n",
       "500364                        No      Ch         Yes         NO  \n",
       "16680                         No      Ch         Yes         NO  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "admissions = pd.read_parquet('../data/interim/notebook1_output.parquet')\n",
    "print(admissions.shape)\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pip requirements for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list --format=freeze > requirements-nb2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do a review of the features available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 101727 entries, 2278392 to 443867222\n",
      "Data columns (total 38 columns):\n",
      " #   Column                    Non-Null Count   Dtype   \n",
      "---  ------                    --------------   -----   \n",
      " 0   patient_nbr               101727 non-null  int64   \n",
      " 1   race                      101727 non-null  object  \n",
      " 2   gender                    101727 non-null  object  \n",
      " 3   age                       101727 non-null  category\n",
      " 4   admission_type_id         101727 non-null  category\n",
      " 5   discharge_disposition_id  101727 non-null  category\n",
      " 6   admission_source_id       101727 non-null  category\n",
      " 7   time_in_hospital          101727 non-null  int64   \n",
      " 8   num_lab_procedures        101727 non-null  int64   \n",
      " 9   num_procedures            101727 non-null  int64   \n",
      " 10  num_medications           101727 non-null  int64   \n",
      " 11  number_outpatient         101727 non-null  int64   \n",
      " 12  number_emergency          101727 non-null  int64   \n",
      " 13  number_inpatient          101727 non-null  int64   \n",
      " 14  diag_1                    101727 non-null  object  \n",
      " 15  diag_2                    101727 non-null  object  \n",
      " 16  diag_3                    101727 non-null  object  \n",
      " 17  number_diagnoses          101727 non-null  int64   \n",
      " 18  max_glu_serum             101727 non-null  object  \n",
      " 19  A1Cresult                 101727 non-null  object  \n",
      " 20  metformin                 101727 non-null  object  \n",
      " 21  repaglinide               101727 non-null  object  \n",
      " 22  nateglinide               101727 non-null  object  \n",
      " 23  chlorpropamide            101727 non-null  object  \n",
      " 24  glimepiride               101727 non-null  object  \n",
      " 25  glipizide                 101727 non-null  object  \n",
      " 26  glyburide                 101727 non-null  object  \n",
      " 27  tolbutamide               101727 non-null  object  \n",
      " 28  pioglitazone              101727 non-null  object  \n",
      " 29  rosiglitazone             101727 non-null  object  \n",
      " 30  acarbose                  101727 non-null  object  \n",
      " 31  miglitol                  101727 non-null  object  \n",
      " 32  tolazamide                101727 non-null  object  \n",
      " 33  insulin                   101727 non-null  object  \n",
      " 34  glyburide-metformin       101727 non-null  object  \n",
      " 35  change                    101727 non-null  object  \n",
      " 36  diabetesMed               101727 non-null  object  \n",
      " 37  readmitted                101727 non-null  object  \n",
      "dtypes: category(4), int64(9), object(25)\n",
      "memory usage: 27.6+ MB\n"
     ]
    }
   ],
   "source": [
    "admissions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## exploration<a id='exploration_start'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check for bias<a id='bias_check'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### race<a id='race'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are demographics present, there is an opportunity to know if any particular group is over or under represented.  Race alone is the first target.  What values are available and what percent of the data does each of these values represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2000 [US Census](https://www2.census.gov/library/publications/decennial/2000/briefs/c2kbr01-01.pdf) reports a full population racial mix of 75.1% white and 12.3% black.\n",
    "\n",
    "The American Diabetes Association [ADA](https://diabetes.org/about-us/statistics/about-diabetes#:~:text=Diabetes%20by%20race%2Fethnicity&text=12.1%25%20of%20non%2DHispanic%20blacks,7.4%25%20of%20non%2DHispanic%20whites) reports that 12.1% of  non-hispanic blacks and 7.4% of non-hispanic whites have diabetes diagnoses.  Ethnicity was not captured in this dataset so cannot be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique race values: ['Caucasian' 'AfricanAmerican' 'Other']\n",
      "expected white fraction: 0.7078017567818881\n",
      "observed white fraction: 0.798421378564756\n",
      "expected black fraction: 0.29219824321811194\n",
      "observed black fraction: 0.201578621435244\n"
     ]
    }
   ],
   "source": [
    "print('unique race values:', admissions.race.unique())\n",
    "twoRace = admissions[admissions.race != 'Other'].copy()\n",
    "twoRace_counts = twoRace.race.value_counts()\n",
    "twoRace_fractions = twoRace.race.value_counts('normalize=True')\n",
    "\n",
    "adj_white_count = twoRace_counts['Caucasian'] * 7.4\n",
    "adj_black_count = twoRace_counts['AfricanAmerican'] * 12.1\n",
    "adj_total = adj_white_count + adj_black_count\n",
    "adj_white_perc = adj_white_count / adj_total\n",
    "adj_black_perc = adj_black_count / adj_total\n",
    "print('expected white fraction:', adj_white_perc)\n",
    "print('observed white fraction:', twoRace_fractions['Caucasian'])\n",
    "print('expected black fraction:', adj_black_perc)\n",
    "print('observed black fraction:', twoRace_fractions['AfricanAmerican'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this dataset unbiased, observations with a race value of \"Caucasian\" should make up ~71% of all observations.  The number of observations over that can be removed at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "count_black = twoRace.race.value_counts()['AfricanAmerican']\n",
    "count_white = twoRace.race.value_counts()['Caucasian']\n",
    "white_to_remove = int(count_white - (count_black / 0.29 - count_black ))\n",
    "raceWhite = twoRace[twoRace['race'] == 'Caucasian']\n",
    "raceWhite = raceWhite.sample(raceWhite.shape[0] - white_to_remove)\n",
    "raceBlack = twoRace[twoRace['race'] == 'AfricanAmerican']\n",
    "twoRace = pd.concat( [raceBlack, raceWhite])\n",
    "twoRace.race.value_counts('normalize=True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### type of diabetes<a id='type'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, statistics vary widely on prevalance of type 1 and type 2 diabetes by gender and age.  In general, males are more likely to have diabetes than females, but the gap between the sexes is smaller for type 1.  This dataset does contain the first 3 diagnoses for each admission.  ICD9 codes for diabetes start with 250.  Are there 250 codes in all or nearly all of the observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace[~(twoRace['diag_1'].str.contains('250')) &\n",
    "        ~(twoRace['diag_2'].str.contains('250')) & \n",
    "        ~(twoRace['diag_3'].str.contains('250')) \n",
    "       ].shape[0] / twoRace.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, 62% of the observations here don't have any diabetes type diagnoses codes included.  Demographic bias corrections end here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demographic visualization <a id='demo_viz'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace['age'] = pd.Categorical(twoRace['age'], ['[0-10)', '[10-20)', '[20-30)', '[30-40)', \n",
    "    '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)',])\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "g = sns.FacetGrid(\n",
    "    twoRace,\n",
    "    col='gender',\n",
    "    row='race',\n",
    "    height=3.5,\n",
    "    sharey=False\n",
    ").map(sns.histplot, 'age')\n",
    "\n",
    "for axes in g.axes.flat:\n",
    "    for label in axes.get_xticklabels():\n",
    "        label.set_rotation(45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These distributions show that the various demographic combinations remaining in the dataset are well represented.  How are these combinations related to the readmission variable?  For this, I'll only be concerned with whether or not readmission happened and not whether or not in happened within 30 days.  I'll look at the readmit rate for each race, gender, age group combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readmitMapping = {'NO': 0, '>30': 1, '<30': 1}\n",
    "twoRace['readmitBinary'] = twoRace['readmitted'].replace(to_replace=readmitMapping)\n",
    "demographic_readmit_mean = twoRace.groupby(['race','age','gender'])\\\n",
    "                           .agg([np.mean])['readmitBinary']\\\n",
    "                           .reset_index()\n",
    "\n",
    "plt.clf()\n",
    "g = sns.FacetGrid(\n",
    "    demographic_readmit_mean,\n",
    "    col='gender',\n",
    "    row='race',\n",
    "    height=3.5,\n",
    "    sharey=False\n",
    ").map(sns.barplot, 'mean', 'age')\n",
    "\n",
    "[axes.set_xlabel('readmit ratio') for axes in g.axes.flat]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demographic readmit ratios <a id='demo_rat'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 notable items here.  \n",
    "1. The 0-10 age group is very different between races\n",
    "3. The 90-100 group has a lower ratio than most other age groups for each race/gender combination.\n",
    "\n",
    "I suspect both of these can be explained with a small sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_counts = twoRace.groupby(['age'])['patient_nbr'].count()\n",
    "demographic_counts = demographic_counts.to_frame().reset_index()\n",
    "demographic_counts[(demographic_counts['age'] == '[0-10)') | \n",
    "                   (demographic_counts['age'] == '[90-100)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The small sample idea does hold for the 0-10 age group, but not the 90-100.  Its possible that the 90-100 age group expires during the admission more often than the others.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace['discharge_disposition_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expiration would fit into the 'Other' category, but so would transferred, etc.  Being discharged to a skilled nursing facility (SNF) or home health could also explain the lack of readmission as these would help with adherence to medical advice given at discharge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_age_counts = twoRace.groupby(['age','discharge_disposition_id'])['patient_nbr'].count()\n",
    "discharge_age_counts = discharge_age_counts.to_frame().reset_index()\n",
    "\n",
    "discharge_age_counts.columns = ['ageGroup','dischargeToCare','count']\n",
    "to_replace = {'Other': False, 'home': False, 'home health': True, 'snf': True}\n",
    "discharge_age_counts['dischargeToCare'] = discharge_age_counts['dischargeToCare'].replace(to_replace)\n",
    "discharge_age_counts = discharge_age_counts.groupby(['ageGroup','dischargeToCare'])['count'].sum()\n",
    "discharge_age_counts = discharge_age_counts.to_frame().reset_index()\n",
    "\n",
    "_ = sns.catplot(data=discharge_age_counts\n",
    "    , x='ageGroup' \n",
    "    , y='count' \n",
    "    , hue='dischargeToCare'\n",
    "    , kind='bar'\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 90-100 age group is the only one where a patient is discharged to care more often than not.  The ratio of discharged to care vs not also increases with age after 30.  What does that look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = discharge_age_counts['count'] / \\\n",
    "         discharge_age_counts.groupby('ageGroup')['count'].transform('sum')\n",
    "no_care = ratios[::2].to_frame().reset_index().drop(columns='index')\n",
    "care = ratios[1::2].to_frame().reset_index().drop(columns='index')\n",
    "\n",
    "age_ratios = pd.concat([no_care, care], axis=1)\n",
    "age_ratios.columns=['no_care', 'care']\n",
    "age_ratios['ageGroup'] = discharge_age_counts['ageGroup'].unique()\n",
    "\n",
    "sns.lineplot(data=pd.melt(age_ratios, ['ageGroup']), x='ageGroup', y='value', hue='variable')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking like a good candidate for a new feature.  Does it have a relationship to readmitted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace['DischargedToCare'] = twoRace['discharge_disposition_id'].replace(to_replace).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2pvalue (rows, columns):\n",
    "    contingency = pd.crosstab(rows, columns)\n",
    "    _, p, _, _ = chi2_contingency(contingency)\n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2pvalue(twoRace.readmitted, twoRace.DischargedToCare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does and this new feature will replace the discharge_disposition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace = twoRace.drop(['discharge_disposition_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### admission source and type <a id='admit_st'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These variables seem potentially redundant.  I will take a look at the frequency of combinations of their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab = pd.crosstab(twoRace['admission_source_id'], twoRace['admission_type_id'])\n",
    "sns.heatmap(crosstab, cmap=sns.cubehelix_palette(as_cmap=True), yticklabels=True, linewidths=0.5)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first item that stands out is that physical referral should be physician referral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace['admission_source_id'] = twoRace['admission_source_id'].cat.rename_categories({'physicial referral': 'physician referral'})\n",
    "twoRace.admission_source_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next item that stands out is that these 2 look to have a strong association and are possibly redundant.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because they are so closely related, I will compare simple logisitic regression models run with the readmitted binary variable and each of these variables independently as well as together to judge the value.  First, I need to encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace.admission_type_id = twoRace.admission_type_id.astype('category')\n",
    "twoRace.admission_source_id = twoRace.admission_source_id.astype('category')\n",
    "\n",
    "AdmissionFeatureSelection = twoRace[['admission_type_id','admission_source_id','readmitBinary']].copy()\n",
    "\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "encoded = encoder.fit_transform(AdmissionFeatureSelection[['admission_type_id','admission_source_id']])\n",
    "\n",
    "afs_encoded = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out())\n",
    "afs_encoded['readmitBinary'] = AdmissionFeatureSelection['readmitBinary'].values\n",
    "afs_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a function to do the regression and return a single metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_logreg (x, y):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(x_train, y_train)\n",
    "    y_pred = logreg.predict(x_test)\n",
    "\n",
    "    label_and_weight = dict(zip(x.columns, logreg.coef_[0]))\n",
    "\n",
    "    return accuracy_score(y_test, y_pred), label_and_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = afs_encoded.readmitBinary\n",
    "\n",
    "admission_type_x = afs_encoded.loc[:, afs_encoded.columns.str.contains('type')]\n",
    "print(admission_type_x.shape)\n",
    "simple_logreg(admission_type_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_source_x = afs_encoded.loc[:, afs_encoded.columns.str.contains('source')]\n",
    "print(admission_source_x.shape)\n",
    "simple_logreg(admission_source_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both = afs_encoded.iloc[:, :-1]\n",
    "simple_logreg(both, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the model using both the admission type and source is more accurate, both will be left in place.  It is also interesting that an emergency admission type means a patient is less likely to be readmitted than an emergency department source.  In hindsight, this is likely because trauma injuries would come through the emergency room and create an emergency admission with a low chance of readmission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preadmission measurements <a id=\"preadmit_metrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### previous encounters <a id=\"prev_enc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details about the patient's interactions with providers in the year before their admission may contain interesting information.  The variables that describe this are num_outpatient, num_emergency, and num_inpatient.  I will start this exploration with histograms to look at the distribution of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(12,4))\n",
    "\n",
    "sns.histplot(twoRace['number_outpatient'], ax=ax[0])\n",
    "sns.histplot(twoRace['number_emergency'], ax=ax[1])\n",
    "sns.histplot(twoRace['number_inpatient'], ax=ax[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all 3 variables, the majority of oberservations have 0 encounters.  These would be better suited as boolean categorical types indicating if the patient had that type of encounter in the previous year or not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace['outpatientTF'] = twoRace.number_outpatient.astype(bool)\n",
    "twoRace['emergencyTF'] = twoRace.number_emergency.astype(bool)\n",
    "twoRace['inpatientTF'] = twoRace.number_inpatient.astype(bool)\n",
    "\n",
    "twoRace = twoRace.drop(['number_outpatient','number_emergency','number_inpatient'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f'{x}: {twoRace[x].mean()}' for x in ['outpatientTF','emergencyTF','inpatientTF']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### glucose measurements<a id=\"glu_meas\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1Cresult and max_glu_serum speak to how well the patient's diabetes is managed.  These could be interesting as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(twoRace.A1Cresult.astype('category').value_counts(), '\\n\\n')\n",
    "print(twoRace.max_glu_serum.astype('category').value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values were sparesely captured and, unfortunately, will need to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace = twoRace.drop(['A1Cresult','max_glu_serum'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numerical descriptions of admission <a id=\"num_\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of variables to explore are the different counts of occurences in during the initial admission.  These include time_in_hospital, num_lab_procedures, num_procedures, num_medications, and num_diagnoses.  At a high level, these describe the number of interventions performed during the admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encounter_attributes = twoRace[['time_in_hospital',\n",
    "                                'num_lab_procedures',\n",
    "                                'num_procedures',\n",
    "                                'num_medications',\n",
    "                                'number_diagnoses']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would first like to see the distribution of these variables.  I will use a box plot and histogram for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_and_hist_int (array):\n",
    "\n",
    "    bins = np.arange(array.min() - 0.5, array.max() + 1.5, 1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "    sns.boxplot(x=array, ax=ax[0], showfliers=True)\n",
    "    sns.histplot(array, ax=ax[1], bins=bins)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    return\n",
    "\n",
    "[box_and_hist_int(encounter_attributes[col]) for col in encounter_attributes.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will make notes on what to explore next for each variable individually.  I will define outliers as outside of the right most boxplot whisker (75th perctile + 1.5 x the Interquartile range).\n",
    "\n",
    "<ul style=\"margin-bottom: 10px;\">\n",
    "    <li>time_in_hopsital</li>\n",
    "    <ul>\n",
    "        <li>there are no zeroes</li>\n",
    "        <li>the distribution looks uniform</li>\n",
    "        <li>there are outliers that will need to be examined</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<ul style=\"margin-bottom: 10px;\">\n",
    "    <li>num_lab_procedures</li>\n",
    "    <ul>\n",
    "        <li>there are no zeroes</li>\n",
    "        <li>something strange is happening at the value 1</li>\n",
    "        <li>the distribution looks nearly normal, except for a long right tail and a large count of \"1\"s</li>\n",
    "        <li>there are many outliers in the long right tail</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "<ul style=\"margin-bottom: 10px;\">\n",
    "    <li>num_procedures</li>\n",
    "    <ul>\n",
    "        <li>many of the observations have a value of 0</li>\n",
    "        <li>the distribution looks uniform</li>\n",
    "        <li>there are outliers that need a closer look</li>\n",
    "    </ul>\n",
    "</ul>    \n",
    "    \n",
    "<ul style=\"margin-bottom: 10px;\">\n",
    "    <li>num_medications</li>\n",
    "    <ul>\n",
    "        <li>there are no zeroes</li>\n",
    "        <li>the distribution looks nearly normal, except for the long right tail</li>\n",
    "        <li>there are many outliers in the right tail</li>\n",
    "    </ul>\n",
    "</ul>  \n",
    "\n",
    "<ul style=\"margin-bottom: 10px;\">\n",
    "    <li>number_diagnoses\n",
    "    <ul>\n",
    "        <li>there are no zeroes</li>\n",
    "        <li>the distribution follows no pattern</li>\n",
    "        <li>the count of observations with a value of 9 is interesting</li>\n",
    "        <li>there will be a few outliers to examine.</li>\n",
    "    </ul>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### time_in_hospital<a id=\"tih\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable represents the number of days in a patient's admission.  Length of stay is a valuable metric for any hospital based analyses and the uniformity of the right tail in the histogram means it would be appropriate to leave any values deemed outliers by the Q3 + 1.5xIQR definition in place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_lab_procedures<a id=\"nlp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first want to make sure that I read the plot correctly and there are no observations with a value of zero in this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_variable = encounter_attributes.num_lab_procedures\n",
    "(focused_variable == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no observations with a value of 0.  \n",
    "\n",
    "The next step is to address the observations with a value of 1.  It seems highly unlikely that an inpatient encounter would result in only 1 lab test.  There isn't anything in the [documentation for the dataset](https://archive-beta.ics.uci.edu/dataset/296/diabetes+130+us+hospitals+for+years+1999+2008) that would explan this.  Its possible there is something in the data.  To explore this, I will create a new binary variable indicating if the observation had 1 lab procedure or more than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_lab_procedure = np.where(focused_variable == 1, True, False)\n",
    "pd.DataFrame(one_lab_procedure).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible that the new one_lab_procedure is correlated to one of the other variables or values.  I will look for this by reviewing the correlation coefficient between one_lab_procedure and the other variables, using one hot encoding for categorical variables.  Diag_1, 2 and 3 will not be included yet as they all have many levels.  These variables will be compared against one_lab_procedure in their section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['time_in_hospital','num_procedures','num_medications','number_diagnoses',\n",
    "            'DischargedToCare', 'outpatientTF','emergencyTF', 'inpatientTF']\n",
    "\n",
    "need_dummies = ['race','gender','age','admission_type_id','admission_source_id',\n",
    "                'metformin','repaglinide','nateglinide','chlorpropamide', 'glimepiride', \n",
    "                'glipizide','glyburide','tolbutamide', 'pioglitazone', 'rosiglitazone', \n",
    "                'acarbose','miglitol','tolazamide', 'insulin', 'glyburide-metformin', \n",
    "                'change','diabetesMed']\n",
    "\n",
    "encoded = encoder.fit_transform(twoRace[need_dummies])\n",
    "corr_df = pd.DataFrame(encoded.toarray(), columns=encoder.get_feature_names_out(), index=twoRace.index)\n",
    "corr_df = pd.concat([corr_df, twoRace[numerics]], axis=1)\n",
    "correlated_features = {}\n",
    "\n",
    "for var in corr_df.columns:\n",
    "    correlation, p_value = pearsonr(corr_df[var], one_lab_procedure)\n",
    "    if abs(correlation) > 0.5:\n",
    "        correlated_features[var] = (correlation, p_value)\n",
    "\n",
    "correlated_features        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No other variable has more than a 0.5 correlation with one_lab_procedure.  This variable will be added to the dataset and the observations with num_lab_procedures = 1 will have this value changed to other values, sampled randomly from the distribution of the rest of the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_one = focused_variable[focused_variable != 1]\n",
    "count_of_ones = (focused_variable == 1).sum()\n",
    "\n",
    "new_values = np.random.choice(not_one, size=count_of_ones)\n",
    "\n",
    "# Replace the 1's in 'num_lab_procedures' with the random values\n",
    "focused_variable[focused_variable == 1] = new_values\n",
    "\n",
    "box_and_hist_int(focused_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This variable has maintained its distribution without 1s and the observations with a true value of 1 have been labeled.  Next, the outliers in the right tail need to be treated.  Would it be appropriate to reassign all high outliers to the value of the right whisker (Q3 + 1.5*IQR)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_info(data):\n",
    "\n",
    "    right_whisker = np.percentile(data, 75) + 1.5 * (np.percentile(data, 75) - np.percentile(data, 25))\n",
    "    reassigned = np.where(data > right_whisker, right_whisker, data)\n",
    "    box_and_hist_int(data)\n",
    "    print(pd.DataFrame(data).describe())\n",
    "    box_and_hist_int(reassigned)\n",
    "    print(pd.DataFrame(reassigned).describe())\n",
    "    print(f'\\nright whisker value: {right_whisker}')\n",
    "\n",
    "iqr_info(focused_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, reassigning the outliers to the right whisker value has little impact on the shape of this variable and any information lost would be offset by removing the undue weight of the outliers.  This variable is an integer and to maintain that, 92 will be used for the max value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_variable = np.where(focused_variable > 92, 92, focused_variable)\n",
    "twoRace['num_lab_procedures'] = focused_variable.copy()\n",
    "twoRace['one_lab_procedure'] = one_lab_procedure.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_procedures<a id=\"np\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_and_hist_int(twoRace['num_procedures'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, this variable should remain untouched.  The small range of values and uniformity should model well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### num_medications<a id=\"nm\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_variable = twoRace['num_medications'].copy()\n",
    "box_and_hist_int(focused_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is has a very long right tail.  Would it be appropriate to pull all of the higher values down to the outer whisker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_info(focused_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems passable, but it does change the mean and standard deviation significantly.  Would a log transformation be more appropriate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_log2 = np.log2(focused_variable)\n",
    "sns.histplot(fv_log2, color='grey')\n",
    "fv_log10 = np.log10(focused_variable)\n",
    "sns.histplot(fv_log10, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log10 transformation results in a more uniform distribution with fewer outliers and seems like the best way to handle the long right tail of num_medications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace['num_medications'] = np.log10(fv_log10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number_diagnoses<a id=\"nd\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_variable = twoRace['number_diagnoses'].copy()\n",
    "box_and_hist_int(focused_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is something interesting happening at 9.  It seems like it could be a result of data collection where most facilities included in the study only keep 9 diagnoses for an admission while a small number of other facilities allow more.  It could also be that a common type of admission among diabetics has a diagnoses set that includes 9 different codes.  If the second option is true, the diag_1, 2 and 3 variables should have common values for many of the observations with 9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nines = focused_variable == 9\n",
    "\n",
    "only_9_dx = twoRace.loc[nines, ['diag_1','diag_2','diag_3']]\n",
    "only_9_dx.value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 400 series codes are heart disase codes, 500s are kidney disease and 276 is a fluid imbalance, commonly seen with kidney disorders.  This has somewhat validated the theory that the 9s could be saved codesets, but this needs to be compared to the full dataset to verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace[['diag_1','diag_2','diag_3']].value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a glance, the top 3 diagnoses of the oberservations with 9 diagnoses are much different than the full set.  This lends more weight to the idea that they are saved codesets.  Are these top 3 diagnoses similar for observations that have 9 total diagnoses and more than 9?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_than_nine = focused_variable > 9\n",
    "more_than_nine = twoRace.loc[more_than_nine, ['diag_1','diag_2','diag_3']]\n",
    "more_than_nine.value_counts().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, every observation with more than 9 diagnoses has different values for diagnoses 1-3.  What does this distribution look like if we apply the q3 + 1.5iqr rule to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqr_info(focused_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems like an acceptable way to handle these outliers.  As partial diagnoses don't make sense, the outlier cutoff value will be rounded to 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace.number_diagnoses = np.where(focused_variable > 14, 14, focused_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diag_1-3<a id=\"dx\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_variable = twoRace[['diag_1','diag_2','diag_3']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 3 diagnoses for the patient's admission will be the next target of this exploration.  These are stored as ICD9 codes that describe a patient's condition.  Knowing how much of each variable is missing or formatted incorrectly would be a good place to start with these.  CMS has a well defined [format](https://www.cms.gov/Medicare/Quality-Initiatives-Patient-Assessment-Instruments/HospitalQualityInits/Downloads/HospitalAppendix_F.pdf) for ICD9 codes.  This is also found in the references folder of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_icd_len(diags):\n",
    "    diags = diags.astype(str)\n",
    "    too_short = (diags.str.len() < 3).sum()\n",
    "    too_long = (diags.str.len() > 6).sum()\n",
    "    return(too_short, too_long)\n",
    "\n",
    "[f'{dx}: {bad_icd_len(focused_variable[dx])}' for dx in focused_variable]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 3 diagnoses variables have values that are too short.  What do these look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{dx: focused_variable[dx][focused_variable[dx].str.len() < 3].sample(n=10) for dx in focused_variable}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these samples, there are 2 issues to address.\n",
    "\n",
    "1. The leading 0 has been removed from the 000-099 series of codes.\n",
    "2. Missing codes have a value of \"?\"\n",
    "\n",
    "Issue 1 will be addressed first by padding the leading zeroes back onto the front of the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in focused_variable.columns:\n",
    "    focused_variable[col] = focused_variable[col].str.zfill(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to explore using Word2Vec to create new features for the diag_x columns.  Missing values should not be included in the training.  I will create 1 sentence per observation that includes all non-missing values from diag_1-3.  In the interest of time, the vector size and workers will be based on my laptop's hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv_no_missing = focused_variable.replace('00?', np.nan).copy()\n",
    "sentences = fv_no_missing.apply(lambda row: row.dropna().tolist(), axis=1).tolist()\n",
    "model = Word2Vec(sentences, vector_size=500, window=2, min_count=1, workers=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new continuous variable will be created and assigned the value of the median of the vectors assigned to each diagnosis word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_dx(dx_list, model):\n",
    "    dx_list = dx_list.tolist()\n",
    "    vectors = [model.wv[dx] for dx in dx_list if dx in model.wv]\n",
    "    return np.median(vectors)\n",
    "\n",
    "fv_no_missing['3dx_vector'] = fv_no_missing[['diag_1','diag_2','diag_3']].apply(lambda row: vec_dx(row, model), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new variable containing the median of the vectors will then have k-means clustering applied to group each unique set of values of diag_1-3 into broader categories that are similar to each other.  The number of clusters was selected based on the highest silhouette score in a reasonable range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.array(fv_no_missing['3dx_vector'].tolist())\n",
    "reshaped_vectors = vectors.reshape(-1, 1)\n",
    "\n",
    "min_clusters = 3\n",
    "max_clusters = 15\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range(min_clusters, max_clusters+1):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    cluster_labels = kmeans.fit_predict(reshaped_vectors)\n",
    "    sihouette_avg = silhouette_score(reshaped_vectors, cluster_labels)\n",
    "    silhouette_scores.append(sihouette_avg)\n",
    "    \n",
    "plt.plot(range(min_clusters, max_clusters+1), silhouette_scores, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Analysis\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=14)\n",
    "cluster_labels = kmeans.fit(reshaped_vectors)\n",
    "cluster_labels = cluster_labels.labels_\n",
    "fv_no_missing['dx_cluster'] =  cluster_labels\n",
    "fv_no_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new feature represents groups of similar diagnoses in each admission.  It will replace diag_1-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace['dx_cluster'] = fv_no_missing['dx_cluster']\n",
    "twoRace = twoRace.drop(['diag_1','diag_2','diag_3'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new feature should also be checked for correlation with one_lab_procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2pvalue(twoRace.one_lab_procedure, twoRace.dx_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is safe to leave the new feature in place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### medications<a id=\"meds\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last set of features to explore are the features that represent whether a particular prescription was continued after the admission or had its dosage changed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_variable = twoRace[['metformin','repaglinide','nateglinide','chlorpropamide','glimepiride','glipizide', \n",
    "                            'glyburide','tolbutamide','pioglitazone','rosiglitazone','acarbose','miglitol', \n",
    "                            'tolazamide','insulin','glyburide-metformin']].copy()\n",
    "\n",
    "for column in focused_variable.columns:\n",
    "    unique_values = focused_variable[column].unique()\n",
    "    print(f'{column}:')\n",
    "    print(unique_values, '\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the levels for these categorical features are 'No', 'Up', 'Steady', and 'Down'. Although there are 3 medications that don't have the complete set of values, they share some of this list and it can be inferred that these were possibilities during data collection. Although there are 3 medications that don't have the complete set of values, they share some of this list and it can be inferred that these were possibilities during data collection.\n",
    "\n",
    "The glyburide-metformin combination could be redundant with the columns for the 2 individual drugs.  If they are redundant, the values across all 3 would match.  If they are not, the value of the combination would be populated (not 'No') and the value of the other 2 would not be (= 'No').  Is this what is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbmt = focused_variable[['metformin','glyburide','glyburide-metformin']]\n",
    "gbmt[gbmt['glyburide-metformin'] != 'No'].groupby(['metformin','glyburide']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the majority of observations, this holds true.  It is possible for patients to have any combination of the prescriptions, but it should be rare.  That is what is seen here and no further action is needed on these variables.  \n",
    "\n",
    "Next, the high dimenstionality of medication variables needs to be addressed.  There are 15 potentially low value variables here.  Encoding these would yield at least 40 total.  Some dimensionality reduction is needed.  Drugs are often grouped into pharmaceutical classes.  Several of the drugs in this list share a pharmaceutical class.  These classes describe the intended effect of the drug on specific body systems.  Patients should not be taking more than one drug of a class.  Let's make sure this is mostly true for this data.  The pharm class data was pulled from [drugbank.com](https://go.drugbank.com/).  As metformin, insulin and glyburide-metformin are in the own classes, these will be left as is.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_classes = {\n",
    "    'metformin': 'Biguanide',\n",
    "    'repaglinide': 'Meglitinide',\n",
    "    'nateglinide': 'Meglitinide',\n",
    "    'chlorpropamide': 'Sulfonylurea',\n",
    "    'glimepiride': 'Sulfonylurea',\n",
    "    'glipizide': 'Sulfonylurea',\n",
    "    'glyburide': 'Sulfonylurea',\n",
    "    'tolbutamide': 'Sulfonylurea',    \n",
    "    'pioglitazone': 'Thiazolidinedione',\n",
    "    'rosiglitazone': 'Thiazolidinedione',\n",
    "    'acarbose': 'Alpha-glucosidase inhibitor',\n",
    "    'miglitol': 'Alpha-glucosidase inhibitor',\n",
    "    'tolazamide': 'Sulfonylurea',\n",
    "    'insulin': 'Hormone',\n",
    "    'glyburide-metformin': 'Combination medication (Sulfonylurea + Biguanide)'\n",
    "}\n",
    "\n",
    "multi_drug_classes = {\n",
    "    'repaglinide': 'Meglitinide',\n",
    "    'nateglinide': 'Meglitinide',\n",
    "    'chlorpropamide': 'Sulfonylurea',\n",
    "    'glimepiride': 'Sulfonylurea',\n",
    "    'glipizide': 'Sulfonylurea',\n",
    "    'glyburide': 'Sulfonylurea',\n",
    "    'tolbutamide': 'Sulfonylurea',    \n",
    "    'pioglitazone': 'Thiazolidinedione',\n",
    "    'rosiglitazone': 'Thiazolidinedione',\n",
    "    'acarbose': 'Alpha-glucosidase inhibitor',\n",
    "    'miglitol': 'Alpha-glucosidase inhibitor',\n",
    "    'tolazamide': 'Sulfonylurea'\n",
    "}\n",
    "\n",
    "to_drop = ['metformin','insulin','glyburide-metformin']\n",
    "focused_variable = focused_variable.drop(to_drop, axis=1)\n",
    "multi_class_locs = []\n",
    "fv_just_mult = focused_variable[list(multi_drug_classes.keys())]\n",
    "\n",
    "for index, row in fv_just_mult.iterrows():\n",
    "    count_by_class = {}\n",
    "    not_no_count = 0\n",
    "\n",
    "    for drug, class_name in multi_drug_classes.items():\n",
    "        value = row[drug]\n",
    "        if value != \"No\":\n",
    "            not_no_count += 1\n",
    "            count_by_class[class_name] = count_by_class.get(class_name, 0) + 1\n",
    "\n",
    "    if not_no_count >= 2 and max(count_by_class.values()) >= 2:\n",
    "        multi_class_locs.append(index)\n",
    "\n",
    "multi_class_obs = fv_just_mult.loc[multi_class_locs]\n",
    "fv_just_mult.loc[multi_class_locs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, this case is rare.  Each of the combinations here involve holding one drug (or more than one from the class) steady and increasing the other.  The net effect of this is that the class was increased.  A new feature with the class name would be \"Up\".  This creates a problem if any of these observations have \"Up\" and \"Down\" in the same class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_indexes = []\n",
    "\n",
    "for index, row in multi_class_obs.iterrows():\n",
    "    class_counts = {}\n",
    "    for drug, class_name in multi_drug_classes.items():\n",
    "        if row[drug] != 'No':\n",
    "            if class_name not in class_counts:\n",
    "                class_counts[class_name] = set()\n",
    "            class_counts[class_name].add(row[drug])\n",
    "\n",
    "    for class_name, drug_values in class_counts.items():\n",
    "        if 'Up' in drug_values and 'Down' in drug_values:\n",
    "            problem_indexes.append(index)\n",
    "\n",
    "multi_class_obs.loc[problem_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1 encounter that meets this criteria can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace = twoRace.drop(index=problem_indexes)\n",
    "focused_variable = focused_variable.drop(index=problem_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the reamining oberservations can have their values collapsed into their respective drug classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_columns(row):\n",
    "    if 'Up' in row.values:\n",
    "        return 'Up'\n",
    "    elif 'Down' in row.values:\n",
    "        return 'Down'\n",
    "    elif 'Steady' in row.values:\n",
    "        return 'Steady'\n",
    "    else:\n",
    "        return 'No'\n",
    "\n",
    "def combine_classes(drug_class):\n",
    "    drugs = [key for key, value in multi_drug_classes.items() if value == drug_class]\n",
    "    rows = focused_variable[drugs].copy()\n",
    "    values = rows.apply(collapse_columns, axis=1)\n",
    "    drug_class += '_class'\n",
    "    focused_variable[drug_class] = values\n",
    "\n",
    "classes = list(set(multi_drug_classes.values()))\n",
    "for drug_class in classes:\n",
    "    combine_classes(drug_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the variables for drugs that share a class with other drugs can also be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [col for col in focused_variable.columns if not col.endswith('_class')]\n",
    "focused_variable = focused_variable.drop(to_drop, axis=1)\n",
    "twoRace = twoRace.drop(to_drop, axis=1)\n",
    "twoRace = twoRace.merge(focused_variable, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the diabetesMed and change variables are redundant with the _class variables.  These can also be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['diabetesMed','change']\n",
    "twoRace = twoRace.drop(to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap-Up<a id=\"wrapUp\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exploratory analysis is complete.  In a high level review, the changes made are:\n",
    "\n",
    "- corrected for race bias\n",
    "- added a new feature 'DischargedToCare'\n",
    "- removed blood sugar measurement columns\n",
    "- added boolean variables for various interactions with healthcare in the preceeding year\n",
    "- transformed outliers in several variables describing aspects of the admission\n",
    "- created a new boolean variable describing if only 1 lab procedure was performed in the admission\n",
    "- clustered diagnoses codes into 9 groups\n",
    "- condensed various drug variables into 4 pharmaceutical classes\n",
    "\n",
    "From here, the resulting dataframe will be optimized for exporting as a parquet file in preparation for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoRace.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['race','gender','metformin','insulin','glyburide-metformin','readmitted']\n",
    "twoRace[categoricals] = twoRace[categoricals].astype('category')\n",
    "twoRace['readmitBinary'] = twoRace.readmitBinary.astype('bool')\n",
    "twoRace.to_parquet(path='../data/interim/notebook2_output.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d6168d7bc7859454aa8ce9bc6837161dc8041b6aaba9ceece6c315f9b1379bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
